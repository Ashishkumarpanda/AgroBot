# -*- coding: utf-8 -*-
"""minor project.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1nSW8GUbyuHOBAovLQLZu_N_iKEk4z-ZK
"""

from google.colab import files
files.upload()

"""# Crop prediction"""

import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt

len

df = pd.read_csv("/content/crop (1).csv")
len(df['temperature'])

df.head()

np.unique(df['Soil Type'])

new_soil = soil*23

s = []
for i in range(2200):
  s.append(new_soil[i])

len(s)

df['Soil Type'] = s
df.to_csv('crop.csv',index=False)

df.head()

np.unique(df['ph'])

np.unique(df['label'])

df['ph'].replace('Neutral',0,inplace=True)
df['ph'].replace('Acid',1,inplace=True)
df['ph'].replace('Base',2,inplace=True)

#Soil Type
df['Soil Type'].replace('Black',0,inplace=True)
df['Soil Type'].replace('Clayey',1,inplace=True)
df['Soil Type'].replace('Loamy',2,inplace=True)
df['Soil Type'].replace('Red',3,inplace=True)
df['Soil Type'].replace('Sandy',4,inplace=True)

df.head()

plt.figure(figsize=(15,10))
sns.heatmap(df.corr(),linewidths=.5,annot=True,fmt=".2g")

x = df.drop('label',axis=1)
y = df['label']

from sklearn.model_selection import train_test_split
x_train,x_test,y_train,y_test = train_test_split(x,y,test_size = 0.3, random_state = 0)

df.info()

df.shape

from sklearn.ensemble import RandomForestClassifier
model = RandomForestClassifier(n_estimators=250)

x

model.fit(x_train,y_train)

model.predict(x_test)

from sklearn.metrics import f1_score
f1_score(y_test,model.predict(x_test),average='micro')

from sklearn.metrics import confusion_matrix
c_m = confusion_matrix(y_test,model.predict(x_test))

plt.figure(figsize=(10,7))
sns.set(font_scale=1.4) # for label size
sns.heatmap(c_m, annot=True, annot_kws={"size": 16}) # font size
plt.legend('Confusion matrix plot')
plt.show()

plt.figure(figsize=(40,20))
plt.plot(y_test,model.predict(x_test))
plt.xlabel("True Value")
plt.ylabel("Predicted value")
plt.title("Crop Prediction Using ML")
plt.show()

import pickle
filename = 'c.pkl'
pickle.dump(model, open(filename, 'wb'))
 
# load the model from disk
loaded_model = pickle.load(open(filename, 'rb'))
result = loaded_model.score(x_test, y_test)
print(result)

"""# Fertilizer prediction"""

df_fert = pd.read_csv("/content/Fertilizer Prediction.csv")
df_fert.head()

drop_val = ['Nitrogen','Phosphorous','Potassium']
df_fert.drop(drop_val,axis=1,inplace=True)

df_fert.head()

np.unique(df_fert['Soil Type'])

np.unique(df_fert['Crop Type'])

#Soil Type
df_fert['Soil Type'].replace('Black',0,inplace=True)
df_fert['Soil Type'].replace('Clayey',1,inplace=True)
df_fert['Soil Type'].replace('Loamy',2,inplace=True)
df_fert['Soil Type'].replace('Red',3,inplace=True)
df_fert['Soil Type'].replace('Sandy',4,inplace=True)

#Crop Type
df_fert['Crop Type'].replace('Barley',0,inplace=True)
df_fert['Crop Type'].replace('Cotton',1,inplace=True)
df_fert['Crop Type'].replace('Ground Nuts',2,inplace=True)
df_fert['Crop Type'].replace('Maize',3,inplace=True)
df_fert['Crop Type'].replace('Millets',4,inplace=True)
df_fert['Crop Type'].replace('Oil seeds',5,inplace=True)
df_fert['Crop Type'].replace('Paddy',6,inplace=True)
df_fert['Crop Type'].replace('Pulses',7,inplace=True)
df_fert['Crop Type'].replace('Sugarcane',8,inplace=True)
df_fert['Crop Type'].replace('Tobacco',9,inplace=True)
df_fert['Crop Type'].replace('Wheat',10,inplace=True)

df_fert.head()

x = df_fert.drop('Fertilizer Name',axis=1)
y = df_fert['Fertilizer Name']

plt.figure(figsize=(15,10))
sns.heatmap(df_fert.corr(),fmt='.2g',annot=True,linewidths=.5)

from sklearn.model_selection import train_test_split

train_x,test_x,train_y,test_y = train_test_split(x,y,test_size=0.3,random_state=0)

from sklearn.ensemble import RandomForestClassifier
tree = RandomForestClassifier(n_estimators=250)

tree.fit(train_x,train_y)

k = tree.predict([[10,20,23,1,2]])

str(k.all())

pred_y = tree.predict(test_x)

f1_score(test_y,pred_y,average='weighted')

plt.figure(figsize=(10,7))
sns.set(font_scale=1.4) # for label size
sns.heatmap(confusion_matrix(test_y,pred_y), annot=True, annot_kws={"size": 16}) # font size
plt.legend('Confusion matrix plot')
plt.show()

plt.figure(figsize=(40,20))
plt.plot(test_y,tree.predict(test_x))
plt.xlabel("True Value")
plt.ylabel("Predicted value")
plt.title("fertilizer Prediction Using ML")
plt.show()

import pickle
filename = 'fertilizer.pkl'
pickle.dump(tree, open(filename, 'wb'))
 
# load the model from disk
loaded_model = pickle.load(open(filename, 'rb'))
result = loaded_model.score(test_x, test_y)
print(result)

"""# Soil type"""

from google.colab import files
files.upload()

! pip install kaggle

! mkdir ~/.kaggle

! cp kaggle.json ~/.kaggle/

! chmod 600 ~/.kaggle/kaggle.json

!kaggle datasets download -d prasanshasatpathy/soil-types

!unzip soil-types.zip

import numpy as np 
import pandas as pd

import os
dir_black = os.path.join('/content/Soil types/Black Soil')
dir_Cinder = os.path.join('/content/Soil types/Cinder Soil')
dir_Laterite = os.path.join('/content/Soil types/Laterite Soil')
dir_peat = os.path.join('/content/Soil types/Peat Soil')
dir_yellow = os.path.join('/content/Soil types/Yellow Soil')

import tensorflow as tf
from tensorflow import keras

image_size = 220
batch_size = 10

target_size = (image_size, image_size)
input_shape = (image_size, image_size, 3)

from tensorflow.keras.preprocessing.image import ImageDataGenerator

train_datagen = ImageDataGenerator(rescale=1/255)


train_generator = train_datagen.flow_from_directory(
        '/content/Soil types', 
        target_size=(200, 200),
        batch_size = batch_size,
        classes = ['Black Soil','Cinder Soil', 'Laterite Soil','Peat Soil','Yellow Soil'],
       class_mode='categorical')

for image_batch, label_batch in train_generator:
  break
  image_batch.shape, label_batch.shape

print (train_generator.class_indices)

model = tf.keras.models.Sequential([
    
    # The first convolution
    tf.keras.layers.Conv2D(16, (3,3), activation='relu', input_shape=(220, 220, 3)),
    tf.keras.layers.MaxPooling2D(2, 2),
    # The second convolution
    tf.keras.layers.Conv2D(32, (3,3), activation='relu'),
    tf.keras.layers.MaxPooling2D(2,2),
    # The third convolution
    tf.keras.layers.Conv2D(64, (3,3), activation='relu'),
    tf.keras.layers.MaxPooling2D(2,2),
    # The fourth convolution
    tf.keras.layers.Conv2D(64, (3,3), activation='relu'),
    tf.keras.layers.MaxPooling2D(2,2),
    # The fifth convolution
    tf.keras.layers.Conv2D(64, (3,3), activation='relu'),
    tf.keras.layers.MaxPooling2D(2,2),
    
    # Flatten the results to feed into a dense layer
    tf.keras.layers.Flatten(),
    # 128 neuron in the fully-connected layer
    tf.keras.layers.Dense(128, activation='relu'),
    # 5 output neurons for 5 classes with the softmax activation
    tf.keras.layers.Dense(5, activation='softmax')
])

model.summary()

from tensorflow.keras.optimizers import RMSprop

model.compile(loss='categorical_crossentropy',
              optimizer=RMSprop(learning_rate=0.001),
              metrics=['acc'])

total_sample = train_generator.n
n_epochs = 30

history = model.fit(
        train_generator, 
        steps_per_epoch = int(total_sample/batch_size),  
        epochs = n_epochs,
        verbose = 1)

import matplotlib.pyplot as plt
plt.figure(figsize=(7,4))
plt.plot([i+1 for i in range(n_epochs)],history.history['acc'],'-o',c='k',lw=2,markersize=9)
plt.grid(True)
plt.title("Training accuracy with epochs\n",fontsize=18)
plt.xlabel("Training epochs",fontsize=15)
plt.ylabel("Training accuracy",fontsize=15)
plt.xticks(fontsize=15)
plt.yticks(fontsize=15)
plt.show()

import pickle
filename = 'soil.pkl'
pickle.dump(model, open(filename, 'wb'))
 
# load the model from disk

loaded_model = pickle.load(open(filename, 'rb'))

import cv2
from google.colab.patches import cv2_imshow

img = cv2.imread('/content/Soil types/Black Soil/10.jpg')
cv2_imshow(img)

reshape = cv2.resize(img,(220,220))
cv2_imshow(reshape)

d = {0:'Black Soil', 1:'Cinder Soil', 2:'Laterite Soil', 3:'Peat Soil', 4:'Yellow Soil'}

img = cv2.imread('/content/Soil types/Cinder Soil/1.jpg')
  reshape = cv2.resize(img,(220,220))
  
  arr = np.array(reshape)
  y = np.expand_dims(arr,axis=0)
  result = loaded_model.predict(y)
  val = list(result[0])
  print(d[val.index(max(val))])

result

